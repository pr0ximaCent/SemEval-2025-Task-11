{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML Models' Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Importing necessary libraries :)\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "import emoji\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import f1_score, classification_report, confusion_matrix\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Downloading stopwords :()\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Defining languages\n",
    "languages = [\"arq\", \"amh\", \"hau\", \"orm\", \"som\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Defining stopwords :) :(\n",
    "stopwords_dict={\n",
    "    \"arq\": set(stopwords.words('arabic')),\n",
    "    \"amh\": set(stopwords.words('english')),  \n",
    "    \"hau\": set(stopwords.words('english')),  \n",
    "    \"orm\": set(stopwords.words('english')),  \n",
    "    \"som\": set(stopwords.words('english')),  \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Text preprocessing function\n",
    "def preprocess_text(text, lang=\"English\"):\n",
    "    # Remove emojis\n",
    "    text = emoji.replace_emoji(text, replace=\"\")\n",
    "    # Remove punctuation\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    words = text.lower().split()\n",
    "    if lang in stopwords_dict:\n",
    "        words = [word for word in words if word not in stopwords_dict[lang]]\n",
    "    \n",
    "    return \" \".join(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def train_models(X_train, y_train, X_dev, y_dev, X_test, test_df, model_params, lang):\n",
    "    models = {\n",
    "        \"Logistic Regression\": LogisticRegression(max_iter=model_params[\"Logistic Regression\"][\"max_iter\"]),\n",
    "        \"Random Forest\": RandomForestClassifier(n_estimators=model_params[\"Random Forest\"][\"n_estimators\"], max_depth=model_params[\"Random Forest\"][\"max_depth\"]),\n",
    "        \"SVM\": SVC(kernel=model_params[\"SVM\"][\"kernel\"], C=model_params[\"SVM\"][\"C\"]),\n",
    "        \"Naive Bayes\": MultinomialNB(alpha=model_params[\"Naive Bayes\"][\"alpha\"])\n",
    "    }\n",
    "    results = {}\n",
    "    for model_name, model in models.items():\n",
    "        print(f\"ðŸ”¹ Training {model_name}...\")\n",
    "        multi_model = MultiOutputClassifier(model)\n",
    "        multi_model.fit(X_train, y_train)\n",
    "        y_dev_pred = multi_model.predict(X_dev)\n",
    "        f1 = f1_score(y_dev, y_dev_pred, average='macro')\n",
    "        y_test_pred = multi_model.predict(X_test)\n",
    "        y_test_pred_df = pd.DataFrame(y_test_pred, columns=[\"anger\", \"disgust\", \"fear\", \"joy\", \"sadness\", \"surprise\"])\n",
    "        \n",
    "        y_test_pred_df[\"id\"] = test_df['id'].values\n",
    "        cols = [\"id\"] + [col for col in y_test_pred_df.columns if col != \"id\"]\n",
    "        y_test_pred_df = y_test_pred_df[cols]\n",
    "        \n",
    "        # Save predictions\n",
    "        predictions_filename = f\"predictions_{lang}_{model_name.replace(' ', '_')}_test.csv\"\n",
    "        y_test_pred_df.to_csv(predictions_filename, index=False)\n",
    "        \n",
    "        results[model_name] = {\n",
    "            \"model\": multi_model,\n",
    "            \"f1_score\": f1,\n",
    "            \"classification_report\": classification_report(y_dev, y_dev_pred),\n",
    "            \"confusion_matrix\": confusion_matrix(y_dev.argmax(axis=1), y_dev_pred.argmax(axis=1))\n",
    "        }\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def solver_function(model_params):\n",
    "    results = {}\n",
    "    for lang in languages:\n",
    "        print(f\"\\nðŸ”¹ Processing {lang}...\")\n",
    "        train_path = f\"train_folder_path/{lang}.csv\"\n",
    "        dev_path = f\"validation_folder_path/{lang}.csv\"\n",
    "        test_path = f\"test_folder_path/{lang}.csv\"\n",
    "        \n",
    "        if not (os.path.exists(train_path) and os.path.exists(dev_path) and os.path.exists(test_path)):\n",
    "            print(f\"Missing dataset for {lang}, processing...\")\n",
    "            continue\n",
    "        \n",
    "        train_df = pd.read_csv(train_path)\n",
    "        dev_df = pd.read_csv(dev_path)\n",
    "        test_df = pd.read_csv(test_path)\n",
    "        \n",
    "        # Preprocessing text columns\n",
    "        train_df['text'] = train_df['text'].apply(lambda x: preprocess_text(str(x), lang))\n",
    "        dev_df['text'] = dev_df['text'].apply(lambda x: preprocess_text(str(x), lang))\n",
    "        test_df['text'] = test_df['text'].apply(lambda x: preprocess_text(str(x), lang))\n",
    "        \n",
    "        emotion_labels = [\"anger\", \"disgust\", \"fear\", \"joy\", \"sadness\", \"surprise\"]\n",
    "        y_train = train_df[emotion_labels].values\n",
    "        y_dev = dev_df[emotion_labels].values\n",
    "        \n",
    "        # Text Vectorization\n",
    "        vectorizer = TfidfVectorizer(max_features=10512)\n",
    "        X_train = vectorizer.fit_transform(train_df['text']).toarray()\n",
    "        X_dev = vectorizer.transform(dev_df['text']).toarray()\n",
    "        X_test = vectorizer.transform(test_df['text']).toarray()\n",
    "        \n",
    "        # Train models and save predictions\n",
    "        lang_results = train_models(X_train, y_train, X_dev, y_dev, X_test, test_df, model_params, lang)\n",
    "        results[lang] = lang_results\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_params={\n",
    "    \"Logistic Regression\": {\"max_iter\": 256},\n",
    "    \"Random Forest\": {\"n_estimators\": 120, \"max_depth\": 12},\n",
    "    \"SVM\": {\"kernel\": \"rbf\", \"C\": 2}, # Linear also used as kernel\n",
    "    \"Naive Bayes\": {\"alpha\": 1.0}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Driver function\n",
    "if __name__ == \"__main__\":\n",
    "    predictions = solver_function(model_params)\n",
    "    print(\"\\n Predictions saved!!!\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [],
   "dockerImageVersionId": 30918,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
